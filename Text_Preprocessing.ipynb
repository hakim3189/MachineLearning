{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnukCwNGtTumH29jIHhJhS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hakim3189/MachineLearning/blob/main/Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case Folding**"
      ],
      "metadata": {
        "id": "QBebCboi8alW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh teks\n",
        "teks_asli = \"Ini Adalah Contoh Teks yang Akan Dikonversi Menjadi Lowercase.\"\n",
        "\n",
        "# Mengubah teks menjadi lowercase\n",
        "teks_lowercase = teks_asli.lower()\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\", teks_asli)\n",
        "print(\"Teks setelah diubah menjadi lowercase:\", teks_lowercase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T-cPhx48UbO",
        "outputId": "38ed8ba8-7f15-4bf1-98e9-ea743924106e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Ini Adalah Contoh Teks yang Akan Dikonversi Menjadi Lowercase.\n",
            "Teks setelah diubah menjadi lowercase: ini adalah contoh teks yang akan dikonversi menjadi lowercase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removal Special Characters**"
      ],
      "metadata": {
        "id": "cO4VK1uM8eoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menghapus angka dari teks\n",
        "def hapus_angka(teks):\n",
        "    teks_tanpa_angka = ''.join([char for char in teks if not char.isdigit()])\n",
        "    return teks_tanpa_angka\n",
        "\n",
        "# Contoh teks dengan angka\n",
        "teks_dengan_angka = \"Ini adalah contoh teks dengan angka 12345 yang akan dihapus.\"\n",
        "\n",
        "# Memanggil fungsi untuk menghapus angka\n",
        "teks_tanpa_angka = hapus_angka(teks_dengan_angka)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks dengan angka:\", teks_dengan_angka)\n",
        "print(\"Teks tanpa angka:\", teks_tanpa_angka)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq8FLyWw8iCY",
        "outputId": "e72e4477-b919-4729-b09a-8fc871422ef2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks dengan angka: Ini adalah contoh teks dengan angka 12345 yang akan dihapus.\n",
            "Teks tanpa angka: Ini adalah contoh teks dengan angka  yang akan dihapus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def hapus_angka_tidak_relevan(teks):\n",
        "    # Menggunakan regex untuk mengidentifikasi dan menghapus angka yang tidak relevan\n",
        "    # Pola untuk mengenali angka yang harus dihapus, termasuk nomor rumah dan nomor telepon\n",
        "    pola_angka_tidak_relevan = r\"\\b(?:\\d{1,3}[-\\.\\s]?)?(?:\\d{3}[-\\.\\s]?)?\\d{4,}\\b\"\n",
        "    hasil = re.sub(pola_angka_tidak_relevan, \"\", teks)\n",
        "    return hasil.strip()\n",
        "\n",
        "# Contoh kalimat dengan angka\n",
        "kalimat = \"Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi 081234567890 untuk informasi lebih lanjut.\"\n",
        "\n",
        "# Memanggil fungsi untuk menghapus angka tidak relevan\n",
        "hasil_tanpa_angka = hapus_angka_tidak_relevan(kalimat)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Kalimat dengan angka:\", kalimat)\n",
        "print(\"Kalimat tanpa angka tidak relevan:\", hasil_tanpa_angka)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bKybRl78voK",
        "outputId": "2352f3e5-4ada-4857-886e-d944e231115a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kalimat dengan angka: Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi 081234567890 untuk informasi lebih lanjut.\n",
            "Kalimat tanpa angka tidak relevan: Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi  untuk informasi lebih lanjut.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Membuat set yang berisi semua tanda baca\n",
        "    punctuation_set = set(string.punctuation)\n",
        "\n",
        "    # Menghapus tanda baca dari teks\n",
        "    text_without_punctuation = ''.join(char for char in text if char not in punctuation_set)\n",
        "\n",
        "    return text_without_punctuation\n",
        "\n",
        "# Contoh teks dengan tanda baca\n",
        "teks_asli = \"Ini adalah contoh teks, dengan tanda baca! Contoh ini, digunakan? untuk demonstrasi.\"\n",
        "\n",
        "# Menghapus tanda baca dari teks\n",
        "teks_tanpa_tanda_baca = remove_punctuation(teks_asli)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\", teks_asli)\n",
        "print(\"Teks setelah menghapus tanda baca:\", teks_tanpa_tanda_baca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MXw_qvP89QA",
        "outputId": "c2d312d0-b5d5-4c34-e0c4-7520f96cabdc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Ini adalah contoh teks, dengan tanda baca! Contoh ini, digunakan? untuk demonstrasi.\n",
            "Teks setelah menghapus tanda baca: Ini adalah contoh teks dengan tanda baca Contoh ini digunakan untuk demonstrasi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teks = \"   Ini adalah contoh kalimat dengan spasi di awal dan akhir.    \"\n",
        "teks_setelah_strip = teks.strip()\n",
        "print(teks_setelah_strip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdlDW50E9DGO",
        "outputId": "516e70da-e743-433e-fa74-97452c31c222"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ini adalah contoh kalimat dengan spasi di awal dan akhir.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teks_dengan_whitespace = \"Ini adalah    contoh kalimat    dengan spasi    di dalamnya.\"\n",
        "teks_tanpa_whitespace = teks_dengan_whitespace.replace(\" \", \"\")\n",
        "print(teks_tanpa_whitespace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS5Kccbb9LDG",
        "outputId": "e1affdd8-d534-4977-80ae-b7837d3b39af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniadalahcontohkalimatdenganspasididalamnya.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stopword Removal (Filtering)**"
      ],
      "metadata": {
        "id": "UPlY_06J9XEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download korpus stopwords bahasa Indonesia dari NLTK jika belum terunduh\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')  # Untuk tokenisasi kata\n",
        "nltk.download('punkt_tab') # Download the missing punkt_tab data\n",
        "\n",
        "\n",
        "teks = \"Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\"\n",
        "\n",
        "# Tokenisasi teks menjadi kata-kata\n",
        "tokens_kata = word_tokenize(teks)\n",
        "\n",
        "# Ambil daftar stopwords bahasa Indonesia dari NLTK\n",
        "stopwords_indonesia = set(stopwords.words('indonesian'))\n",
        "\n",
        "# Filtering kata-kata dengan menghapus stopwords\n",
        "kata_penting = [kata for kata in tokens_kata if kata.lower() not in stopwords_indonesia]\n",
        "\n",
        "# Gabungkan kata-kata penting kembali menjadi teks\n",
        "teks_tanpa_stopwords = ' '.join(kata_penting)\n",
        "\n",
        "print(\"Teks asli:\", teks)\n",
        "print(\"Teks setelah filtering stopwords NLTK:\", teks_tanpa_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoT6aGIy9YXi",
        "outputId": "98492047-ea4d-4a1a-d3c8-8fb92fcb74f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\n",
            "Teks setelah filtering stopwords NLTK: Perekonomian Indonesia pertumbuhan membanggakan .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Sastrawi library if not already installed\n",
        "!pip install Sastrawi\n",
        "\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Inisialisasi objek StopWordRemover dari Sastrawi\n",
        "factory = StopWordRemoverFactory()\n",
        "stopwords_sastrawi = factory.get_stop_words()\n",
        "\n",
        "teks = \"Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\"\n",
        "\n",
        "# Tokenisasi teks menjadi kata-kata\n",
        "tokens_kata = word_tokenize(teks)\n",
        "\n",
        "# Filtering kata-kata dengan menghapus stopwords Sastrawi\n",
        "kata_penting = [kata for kata in tokens_kata if kata.lower() not in stopwords_sastrawi]\n",
        "\n",
        "# Gabungkan kata-kata penting kembali menjadi teks\n",
        "teks_tanpa_stopwords = ' '.join(kata_penting)\n",
        "\n",
        "print(\"Teks asli:\", teks)\n",
        "print(\"Teks setelah filtering stopwords Sastrawi:\", teks_tanpa_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TToax6SU93v9",
        "outputId": "eb9ec64d-56c5-4849-d8a6-e5ff027747f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m204.8/209.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Teks asli: Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\n",
            "Teks setelah filtering stopwords Sastrawi: Perekonomian Indonesia sedang pertumbuhan membanggakan .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizing**"
      ],
      "metadata": {
        "id": "GT6BUoAh99Af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Ini adalah contoh tokenisasi kata dalam pemrosesan teks.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWZPc-3H9-Ko",
        "outputId": "eef4cbc0-695e-43c9-cdbd-8debc55692c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini', 'adalah', 'contoh', 'tokenisasi', 'kata', 'dalam', 'pemrosesan', 'teks', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Pemrosesan teks adalah cabang ilmu komputer yang berfokus pada pengolahan teks dan dokumen. Jadi tolong jadikan ini sebagai dasar\"\n",
        "phrases = text.split(',')\n",
        "print(phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZNR1LLC-EDD",
        "outputId": "8dfeb3aa-8b62-4245-8746-828d3178ff89"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pemrosesan teks adalah cabang ilmu komputer yang berfokus pada pengolahan teks dan dokumen. Jadi tolong jadikan ini sebagai dasar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Pertama, kita perlu menyiapkan bahan-bahan yang diperlukan.\"\n",
        "tokens = re.findall(r'\\w+|\\d+', text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLPYZzNp-JbZ",
        "outputId": "1e94804d-672b-4655-cf47-697b45c31415"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pertama', 'kita', 'perlu', 'menyiapkan', 'bahan', 'bahan', 'yang', 'diperlukan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {
        "id": "xXl5N0Fb-anf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Inisialisasi stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Kata-kata asli\n",
        "words = [\"running\", \"runs\", \"runner\", \"ran\", \"easily\", \"fairness\", \"better\", \"best\", \"cats\", \"cacti\", \"geese\", \"rocks\", \"oxen\"]\n",
        "\n",
        "# Melakukan stemming pada setiap kata\n",
        "for word in words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    print(f\"Kata asli: {word}, Kata setelah stemming: {stemmed_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAXnML9K-dFL",
        "outputId": "f236a65f-1f60-44be-c270-23435a012ba3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kata asli: running, Kata setelah stemming: run\n",
            "Kata asli: runs, Kata setelah stemming: run\n",
            "Kata asli: runner, Kata setelah stemming: runner\n",
            "Kata asli: ran, Kata setelah stemming: ran\n",
            "Kata asli: easily, Kata setelah stemming: easili\n",
            "Kata asli: fairness, Kata setelah stemming: fair\n",
            "Kata asli: better, Kata setelah stemming: better\n",
            "Kata asli: best, Kata setelah stemming: best\n",
            "Kata asli: cats, Kata setelah stemming: cat\n",
            "Kata asli: cacti, Kata setelah stemming: cacti\n",
            "Kata asli: geese, Kata setelah stemming: gees\n",
            "Kata asli: rocks, Kata setelah stemming: rock\n",
            "Kata asli: oxen, Kata setelah stemming: oxen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**"
      ],
      "metadata": {
        "id": "udEFnHyt-oI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download wordnet jika belum di-download\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Inisialisasi lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Kata-kata asli\n",
        "words = [\"running\", \"easily\", \"bought\", \"crying\", \"leaves\"]\n",
        "\n",
        "# Melakukan lematisasi pada setiap kata\n",
        "for word in words:\n",
        "    lemma_word = lemmatizer.lemmatize(word.lower())  # Mengonversi ke huruf kecil untuk memastikan pemrosesan yang konsisten\n",
        "    print(f\"Kata asli: {word}, Kata setelah lematisasi: {lemma_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sntzSdJQ-pZi",
        "outputId": "6e914209-e14d-452a-d526-acb56595a537"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kata asli: running, Kata setelah lematisasi: running\n",
            "Kata asli: easily, Kata setelah lematisasi: easily\n",
            "Kata asli: bought, Kata setelah lematisasi: bought\n",
            "Kata asli: crying, Kata setelah lematisasi: cry\n",
            "Kata asli: leaves, Kata setelah lematisasi: leaf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}